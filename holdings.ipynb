{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hedge Fund Holdings Analysis via EDGAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_edgar_downloader import Downloader\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = Downloader(\"Narain Nair\", \"nair4986@gmail.com\")\n",
    "dl.get(\"13F-HR\", \"1167483\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse and Structure Filing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_table_xml(txt_file_path):\n",
    "    \"\"\"\n",
    "    Extracts the XML string within <INFORMATIONTABLE> tags from the full .txt filing.\n",
    "    \"\"\"\n",
    "    with open(txt_file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Use regex to extract everything between <INFORMATIONTABLE>...</INFORMATIONTABLE>\n",
    "    match = re.search(r\"<INFORMATIONTABLE[\\s\\S]*?</INFORMATIONTABLE>\", content, re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None  # No XML found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_info_table_xml(xml_string):\n",
    "    \"\"\"\n",
    "    Parses the extracted XML string into a list of holdings as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    xml_string_clean = re.sub(r'\\sxmlns=\"[^\"]+\"', '', xml_string, count=1)\n",
    "\n",
    "    root = ET.fromstring(xml_string_clean)\n",
    "\n",
    "    data = []\n",
    "    for info in root.findall(\"infoTable\"):\n",
    "        row = {}\n",
    "        for child in info:\n",
    "            if list(child):  # tag has nested children\n",
    "                for subchild in child:\n",
    "                    tag = subchild.tag.strip()\n",
    "                    text = subchild.text.strip() if subchild.text else ''\n",
    "                    row[tag] = text\n",
    "            else:\n",
    "                tag = child.tag.strip()\n",
    "                text = child.text.strip() if child.text else ''\n",
    "                row[tag] = text\n",
    "        data.append(row)\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_2016(folder_name):\n",
    "    match = re.search(r'-([0-9]{2})-', folder_name)\n",
    "    if match:\n",
    "        year_suffix = int(match.group(1))\n",
    "        year = 2000 + year_suffix\n",
    "        return year > 2016\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(accession):\n",
    "    match = re.search(r'(\\d{4})(\\d{2})(\\d{2})', accession)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}-{match.group(2)}-{match.group(3)}\"\n",
    "    else:\n",
    "        return accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-20-007148/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-24-004713/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-18-001706/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-22-006727/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-20-005337/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-18-005626/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-23-001481/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-21-007099/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-25-003217/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-19-001612/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-24-001349/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-22-005053/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-20-003646/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-21-005372/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-17-001974/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-22-001371/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-17-006218/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-18-007445/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-19-005381/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-25-001475/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-24-006690/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-23-006372/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-19-003690/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-21-003697/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-17-004286/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-19-007198/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-23-003305/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-23-004771/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-21-001376/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-17-008069/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-20-001541/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-18-003754/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-24-003172/full-submission.txt\n",
      "Processing: ./sec-edgar-filings/0001167483/13F-HR/0000919574-22-003470/full-submission.txt\n"
     ]
    }
   ],
   "source": [
    "## Constructing dictionaries for the holdings and the filings themselves\n",
    "folder_path = \"./sec-edgar-filings/0001167483/13F-HR/\"\n",
    "holdings = []\n",
    "filings = []\n",
    "\n",
    "for folder in os.listdir(folder_path):\n",
    "    if not filter_2016(folder):\n",
    "        continue\n",
    "\n",
    "    access_folder_path = os.path.join(folder_path, folder)\n",
    "\n",
    "    for file in os.listdir(access_folder_path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(access_folder_path, file)\n",
    "            print(f\"Processing: {file_path}\")\n",
    "            \n",
    "            xml_str = extract_info_table_xml(file_path)\n",
    "            if xml_str:\n",
    "                df = parse_info_table_xml(xml_str)\n",
    "                df[\"source_file\"] = file\n",
    "                df[\"accession\"] = folder\n",
    "\n",
    "                date_str = extract_date(folder)\n",
    "                filings.append({'date': date_str, 'df':df})\n",
    "                holdings.append(df)\n",
    "\n",
    "master_holdings_df = pd.concat(holdings, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data processing & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting some of the columns to numeric datatypes.\n",
    "cols_for_numeric = ['value', 'sshPrnamt', 'Sole', 'Shared', 'None']\n",
    "for col in cols_for_numeric:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df['%_allocation'] = 100 * (df['value'] / df['value'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to extract the filing date from the path.\n",
    "def filing_date_extraction(path):\n",
    "    match = re.search(r'(\\d{4}-\\d{2}-\\d{2}', path)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Portfolio-level metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the allocation percentage per filing for each holding in portfolio\n",
    "df = df.dropna(subset=['value'])\n",
    "total_value = df['value'].sum()\n",
    "\n",
    "df['allocation_percent'] = (df['value'] / total_value) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdings_compare(df_1, df_2):\n",
    "    prev_set = set(df_1['cusip'])\n",
    "    curr_set = set(df_2['cusip'])\n",
    "\n",
    "    new_buys = curr_set - prev_set\n",
    "    full_exits = prev_set - curr_set\n",
    "    kept = prev_set & curr_set\n",
    "\n",
    "    return {\n",
    "        'new_buys':len(new_buys),\n",
    "        'exits':len(full_exits),\n",
    "        'kept':len(kept),\n",
    "        'total_prev':len(prev_set),\n",
    "        'total_curr':len(curr_set),\n",
    "        'turnover_pct':(len(new_buys | full_exits) / ((len(prev_set) + len(curr_set))/2)) * 100\n",
    "    }\n",
    "\n",
    "turnover_results = []\n",
    "for i in range(1, len(filings)):\n",
    "    prev = filings[i-1]\n",
    "    curr = filings[i]\n",
    "    comparison = holdings_compare(prev['df'], curr['df'])\n",
    "    comparison['period'] = f\"{prev['date']} -> {curr['date']}\"\n",
    "    turnover_results.append(comparison)\n",
    "\n",
    "turnover_df = pd.DataFrame(turnover_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
