{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hedge Fund Holdings Analysis via EDGAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_edgar_downloader import Downloader\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Latest 13F Filing (Tiger Global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the 13F Filings into a specific directory, for Tiger Global specifically.\n",
    "\n",
    "dir = \"sec\"\n",
    "email = \"nair4986@gmail.com\"\n",
    "dl = Downloader(dir, email)  \n",
    "\n",
    "tiger_global_cik = \"0001167483\"\n",
    "\n",
    "dl.get(\"13F-HR\", tiger_global_cik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse and Structure Filing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating the most recent filing out of all the Tiger Global filings in the directory\n",
    "base_path = \"sec-edgar-filings/0001167483/13F-HR\"\n",
    "filing_dates = sorted(os.listdir(base_path), reverse=True)\n",
    "latest_filing = os.path.join(base_path, filing_dates[0], \"full-submission.txt\")\n",
    "\n",
    "# Reading the contents of the file and storing it in memory as a string called 'content'\n",
    "with open(latest_filing, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Each filing will store an XML section that contains all the holding data for the hedge fund\n",
    "# This step extracts the XML data from the file we are parsing in\n",
    "start_tag = \"<informationTable>\"\n",
    "end_tag = \"</informationTable>\"\n",
    "\n",
    "start_index = content.find(start_tag)\n",
    "end_index = content.find(end_tag) + len(end_tag) \n",
    "xml_str = content[start_index:end_index]\n",
    "\n",
    "# XML string is parsed and the rows are extracted\n",
    "soup = BeautifulSoup(xml_str, \"xml\")\n",
    "rows = soup.find_all(\"infoTable\")\n",
    "\n",
    "# Each holding is converted into a dictionary \n",
    "# The key data fields are extracted and we form Key=Value pairs from them.\n",
    "data = []\n",
    "for row in rows:\n",
    "    data.append({\n",
    "        \"Name of Issuer\": row.find(\"nameOfIssuer\").text,\n",
    "        \"CUSIP\": row.find(\"cusip\").text,\n",
    "        \"Shares\": int(row.find(\"sshPrnamt\").text),\n",
    "        \"Share Type\": row.find(\"sshPrnamtType\").text,\n",
    "        \"Investment Discretion\": row.find(\"investmentDiscretion\").text,\n",
    "        \"Other Manager\": row.find(\"otherManager\").text if row.find(\"otherManager\") else None,\n",
    "        \"Voting Authority (Sole)\": row.find(\"Sole\").text if row.find(\"Sole\") else None,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping over all available submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same process as above is repeated, but through ALL possible filings within the SEC edgar filings.\n",
    "\n",
    "filing_data = {}\n",
    "\n",
    "for folder in sorted(os.listdir(base_path)):\n",
    "    filing_path = os.path.join(base_path, folder, \"full-submission.txt\")\n",
    "\n",
    "    if not os.path.exists(filing_path):\n",
    "        continue \n",
    "\n",
    "    with open(filing_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    start_tag = \"<informationTable>\"\n",
    "    end_tag = \"</informationTable>\"\n",
    "\n",
    "    start_index = content.find(start_tag)\n",
    "    end_index = content.find(end_tag) + len(end_tag) \n",
    "    xml_str = content[start_index:end_index]\n",
    "\n",
    "    soup = BeautifulSoup(xml_str, \"xml\")\n",
    "    rows = soup.find_all(\"infoTable\")\n",
    "\n",
    "    holdings = []\n",
    "    for row in rows:\n",
    "        holdings.append({\n",
    "        \"Name of Issuer\": row.find(\"nameOfIssuer\").text,\n",
    "        \"CUSIP\": row.find(\"cusip\").text,\n",
    "        \"Shares\": int(row.find(\"sshPrnamt\").text),\n",
    "        \"Share Type\": row.find(\"sshPrnamtType\").text,\n",
    "        \"Investment Discretion\": row.find(\"investmentDiscretion\").text,\n",
    "        \"Other Manager\": row.find(\"otherManager\").text if row.find(\"otherManager\") else None,\n",
    "        \"Voting Authority (Sole)\": row.find(\"Sole\").text if row.find(\"Sole\") else None,\n",
    "        })\n",
    "\n",
    "    filing_data[folder] = holdings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
